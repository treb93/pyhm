{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.data.utils import save_graphs\n",
    "from environment import Environment\n",
    "from parameters import Parameters\n",
    "from src.classes.dataset import Dataset\n",
    "from src.get_embeddings import get_embeddings\n",
    "from src.max_margin_loss import max_margin_loss\n",
    "from src.model.conv_model import ConvModel\n",
    "from src.train_loop import train_loop\n",
    "\n",
    "from src.utils_data import assign_graph_features\n",
    "from src.utils import read_data, save_txt, save_outputs\n",
    "from src.utils_vizualization import plot_train_loss\n",
    "from src.metrics import (create_already_bought, create_ground_truth,\n",
    "                         get_metrics_at_k, get_recommendation_tensor, precision_at_k)\n",
    "from src.evaluation import explore_recs, explore_sports, check_coverage\n",
    "from presplit import presplit_data\n",
    "\n",
    "from logging_config import get_logger\n",
    "\n",
    "log = get_logger(__name__)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données et du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment()\n",
    "parameters = Parameters({\n",
    "    'aggregator_hetero': 'mean',\n",
    "    'aggregator_type': 'mean',\n",
    "    'clicks_sample': 0.3,\n",
    "    'delta': 0.266,\n",
    "    'dropout': 0.01,\n",
    "    'hidden_dim': 256,\n",
    "    'out_dim': 128,\n",
    "    'embedding_layer': True,\n",
    "    'edge_batch_size': 2048,\n",
    "    'embedding_batch_size': 2048,\n",
    "    'lr': 0.00017985194246308484,\n",
    "    'n_layers': 4,\n",
    "    'neg_sample_size': 10,\n",
    "    'norm': True,\n",
    "    'use_popularity': True,\n",
    "    'weight_popularity': 0.5,\n",
    "    'days_popularity': 7,\n",
    "    'purchases_sample': 0.5,\n",
    "    'prediction_layer': 'cos',\n",
    "    'use_recency': True,\n",
    "    'num_workers': 1,\n",
    "    \"partial_sampling_num_neighbors\" : 5,\n",
    "    'num_epochs': 20\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full train set\n",
    "dataset = Dataset(\n",
    "    environment, parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.graphs import Graphs\n",
    "\n",
    "graphs = Graphs(dataset, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer': 19, 'article': 600, 'edge': 5, 'out': 128, 'hidden': 256}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.get_dimension_dictionnary import get_dimension_dictionnary\n",
    "\n",
    "dim_dict = get_dimension_dictionnary(graphs, parameters)\n",
    "dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.dataloaders import DataLoaders\n",
    "\n",
    "dataloaders = DataLoaders(graphs,\n",
    "                    dataset,\n",
    "                    parameters,\n",
    "                    environment\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvModel(dim_dict,\n",
    "                    parameters\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20\n",
      "Starting training.\n",
      "Epoch 00000 || TRAINING Loss 0.04450 | Precision at k 0.013% || VALIDATION Loss 0.26514 | Precision at k 0.014% \n",
      "Epoch took 0:00:47.045556 \n",
      "\n",
      " Process valid batches...              Epoch 00001 | Training Loss 0.04375 | Validation Loss 0.26514 | \n",
      "Epoch took 0:00:06.289339 \n",
      "\n",
      "Process valid batch 22 / 27             Epoch 00002 | Training Loss 0.04312 | Validation Loss 0.25957 | \n",
      "Epoch took 0:00:07.133943 \n",
      "\n",
      "Train batch 1 / 27 : Get embeddings...                   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34185/256806983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trained_model, viz, best_metrics = train_loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/www/datascientest/pyhm/gnn/src/train_loop.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, dataset, graphs, dataloaders, loss_fn, parameters, environment, get_metrics)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\rTrain batch {i} / {dataloaders.num_batches_train} : Get embeddings...                   \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 embeddings = model.get_embeddings(graphs.history_graph, {\n\u001b[0m\u001b[1;32m     92\u001b[0m                     \u001b[0;34m'article'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0;34m'customer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/www/datascientest/pyhm/gnn/src/model/conv_model.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, graph_or_blocks, h)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_or_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_or_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dgl/nn/pytorch/hetero.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 dstdata = self.mods[etype](\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0mrel_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/www/datascientest/pyhm/gnn/src/model/conv_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, h)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_self\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_neigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_neigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model, viz, best_metrics = train_loop(\n",
    "    model=model,\n",
    "    graphs=graphs,\n",
    "    dataset=dataset,\n",
    "    dataloaders=dataloaders,\n",
    "    loss_fn=max_margin_loss,\n",
    "    get_metrics=True,\n",
    "    parameters=parameters,\n",
    "    environment=environment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing valid recommendations for customers 43200 - 43400"
     ]
    }
   ],
   "source": [
    "                \n",
    "batch_index = 0\n",
    "valid_precision_at_k = 0\n",
    "\n",
    "customers_per_batch = 200\n",
    "current_index = 0\n",
    "length = len(dataset.customers_nid_valid)\n",
    "\n",
    "precision_list = np.array([])\n",
    "recommendation_chunks = []\n",
    "\n",
    "while current_index < length :\n",
    "    \n",
    "    customer_nids = dataset.customers_nid_valid[current_index: current_index + customers_per_batch]\n",
    "    \n",
    "    print(f\"\\rProcessing valid recommendations for customers {current_index} - {current_index + customers_per_batch}\", end = \"\")\n",
    "    new_recommendations = get_recommendation_tensor({\n",
    "        'article': graphs.prediction_graph.nodes['article'].data['h'].to(environment.device),\n",
    "        'customer': graphs.prediction_graph.nodes['customer'].data['h'][customer_nids].to(environment.device),\n",
    "    }, parameters, environment)\n",
    "    \n",
    "    recommendation_chunks.append(new_recommendations)\n",
    "\n",
    "    if current_index % 5000 == 0:\n",
    "        recommendations = torch.cat(recommendation_chunks, dim = 0)\n",
    "        \n",
    "        precision = precision_at_k(recommendations, customer_nids, dataset)\n",
    "        precision_list = np.append(precision_list, precision)\n",
    "        \n",
    "        recommendation_chunks = []\n",
    "    \n",
    "    current_index += customers_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13797"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.customers_nid_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], device='cuda:0', size=(0, 12), dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_nids = dataset.customers_nid_valid[20000:20200]\n",
    "new_recommendations = get_recommendation_tensor({\n",
    "    'article': graphs.prediction_graph.nodes['article'].data['h'].to(environment.device),\n",
    "    'customer': graphs.prediction_graph.nodes['customer'].data['h'][customer_nids].to(environment.device),\n",
    "}, parameters, environment)\n",
    "new_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29251/3309820171.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m opt = parameters.optimizer(model.parameters(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                             lr=parameters.lr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "opt = parameters.optimizer(model.parameters(),\n",
    "                            lr=parameters.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.get_embeddings(graphs.history_graph, {\n",
    "    'article': graphs.history_graph.nodes['article'].data['features'],\n",
    "    'customer': graphs.history_graph.nodes['customer'].data['features'],\n",
    "})\n",
    "\n",
    "graphs.prediction_graph.nodes['article'].data['h'] = embeddings['article'][0:graphs.prediction_graph.num_nodes('article')]\n",
    "graphs.prediction_graph.nodes['customer'].data['h'] = embeddings['customer'][0:graphs.prediction_graph.num_nodes('customer')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7faf05afe6a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings:  tensor([[0.0000, 0.0000, 0.0382,  ..., 0.0000, 0.0061, 0.0831],\n",
      "        [0.0000, 0.0833, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0164, 0.0000, 0.0855,  ..., 0.0000, 0.0138, 0.1343],\n",
      "        ...,\n",
      "        [0.0000, 0.1210, 0.0000,  ..., 0.0711, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0666,  ..., 0.0253, 0.0000, 0.0834],\n",
      "        [0.0000, 0.0000, 0.0502,  ..., 0.0000, 0.0074, 0.0970]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _, pos_g, neg_g, blocks in dataloaders.dataloader_train_loss:\n",
    "    break\n",
    "\n",
    "\n",
    "pos_score, neg_score = model(pos_g, neg_g, graphs.history_graph, {\n",
    "    'article': graphs.history_graph.nodes['article'].data['features'],\n",
    "    'customer': graphs.history_graph.nodes['customer'].data['features'],\n",
    "})\n",
    "\n",
    "                                \n",
    "pos_score = torch.nan_to_num(pos_score, 0)\n",
    "neg_score = torch.nan_to_num(neg_score, 0)\n",
    "\n",
    "loss = max_margin_loss(pos_score,\n",
    "                neg_score,\n",
    "                parameters=parameters,\n",
    "                environment=environment\n",
    "                )\n",
    "\n",
    "loss.backward()\n",
    "opt.step()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_loss_list = []\n",
    "model.train_precision_list = []\n",
    "model.train_recall_list = []\n",
    "model.train_coverage_list = []\n",
    "model.val_loss_list = []\n",
    "model.val_precision_list = []\n",
    "model.val_recall_list = []\n",
    "model.val_coverage_list = []\n",
    "best_metrics = {}  # For visualization\n",
    "max_metric = -0.1\n",
    "patience_counter = 0  # For early stopping\n",
    "min_loss = 1.1\n",
    "\n",
    "opt = parameters.optimizer(model.parameters(),\n",
    "                            lr=parameters.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement (1 itération)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosinePrediction()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict.to(environment.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "opt.zero_grad()\n",
    "\n",
    "embeddings = model(graphs.history_graph, {\n",
    "    'article': graphs.history_graph.nodes['article'].data['features'],\n",
    "    'customer': graphs.history_graph.nodes['customer'].data['features'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.prediction_graph.nodes['article'].data['h'] = embeddings['article'][0:graphs.prediction_graph.num_nodes('article')]\n",
    "graphs.prediction_graph.nodes['customer'].data['h'] = embeddings['customer'][0:graphs.prediction_graph.num_nodes('customer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = torch.tensor([]).to(environment.device)\n",
    "neg_score = torch.tensor([]).to(environment.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosinePrediction()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict.to(environment.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Block(num_src_nodes={'article': 2937, 'customer': 3691},\n",
      "      num_dst_nodes={'article': 2937, 'customer': 3691},\n",
      "      num_edges={('customer', 'buys', 'article'): 0},\n",
      "      metagraph=[('customer', 'article', 'buys')])]\n"
     ]
    }
   ],
   "source": [
    "for _, pos_g, neg_g, blocks in dataloaders.dataloader_train_loss:\n",
    "    print(blocks)\n",
    "    break\n",
    "    pos_g.to(environment.device)\n",
    "    neg_g.to(environment.device)\n",
    "    #\n",
    "    pos_score = torch.cat([pos_score, model.predict(pos_g).to(environment.device)], dim = 0)\n",
    "    #\n",
    "    neg_g.nodes['article'].data['h'] = graphs.history_graph.nodes['article'].data['h'][neg_g.nodes['article'].data['_ID'].long()]\n",
    "    neg_g.nodes['customer'].data['h'] = graphs.history_graph.nodes['customer'].data['h'][neg_g.nodes['customer'].data['_ID'].long()]\n",
    "    #\n",
    "    neg_score = torch.cat([neg_score, model.predict(neg_g).to(environment.device)], dim = 0)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = torch.nan_to_num(pos_score, 0)\n",
    "neg_score = torch.nan_to_num(neg_score, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = max_margin_loss(pos_score,\n",
    "                           neg_score,\n",
    "                           parameters=parameters,\n",
    "                           environment=environment\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing recommendations for customers 25400 - 25600"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4647/590799451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\rProcessing recommendations for customers {current_index} - {current_index + customers_per_batch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     new_recommendations = get_recommendation_tensor({\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m'article'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;34m'customer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcustomers_per_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     }, parameters, environment)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "customers_per_batch = 200\n",
    "current_index = 0\n",
    "length = graphs.prediction_graph.num_nodes('customer')\n",
    "\n",
    "precision_list = np.array([])\n",
    "recommendation_chunks = []\n",
    "\n",
    "while current_index < length :\n",
    "    \n",
    "    print(f\"\\rProcessing recommendations for customers {current_index} - {current_index + customers_per_batch}\", end = \"\")\n",
    "    new_recommendations = get_recommendation_tensor({\n",
    "        'article': graphs.prediction_graph.nodes['article'].data['h'].to(environment.device),\n",
    "        'customer': graphs.prediction_graph.nodes['customer'].data['h'][current_index: current_index + customers_per_batch].to(environment.device),\n",
    "    }, parameters, environment)\n",
    "    \n",
    "    recommendation_chunks.append(new_recommendations)\n",
    "\n",
    "    customer_nids = range(current_index, current_index + customers_per_batch)\n",
    "\n",
    "\n",
    "    if current_index % 5000 == 0:\n",
    "        recommendations = torch.cat(recommendation_chunks, dim = 0)\n",
    "        \n",
    "        precision = precision_at_k(recommendations, customer_nids, dataset)\n",
    "        precision_list = np.append(precision_list, precision)\n",
    "        \n",
    "        recommendation_chunks = []\n",
    "    \n",
    "    current_index += customers_per_batch\n",
    "    \n",
    "precision = np.mean(precision_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation des recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.embedding_on_full_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(environment, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.graphs import Graphs\n",
    "\n",
    "graphs = Graphs(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classes.dataloaders import DataLoaders\n",
    "\n",
    "dataloaders = DataLoaders(graphs,\n",
    "                    dataset,\n",
    "                    parameters,\n",
    "                    environment\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([3195, 256])\n",
      "layer 1\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([0, 256])\n",
      "layer 2\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([0, 256])\n",
      "layer 3\n",
      "torch.Size([1000, 128])\n",
      "torch.Size([0, 128])\n"
     ]
    }
   ],
   "source": [
    "for input_nodes, output_nodes, blocks in dataloaders.dataloader_embedding:\n",
    "    embeddings = model.forward(blocks, blocks[0].srcdata['features'])\n",
    "    \n",
    "    if 'customer' in output_nodes.keys():\n",
    "        graphs.history_graph.nodes['customer'].data['h'][output_nodes['customer'].long()] = embeddings['customer']\n",
    "    \n",
    "    if 'article' in output_nodes.keys():\n",
    "        graphs.history_graph.nodes['article'].data['h'][output_nodes['article'].long()] = embeddings['article']\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "556b15acb71fbccb0059bce8ff607ae84b982497bd2dd0381fcb515435bd8f90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
